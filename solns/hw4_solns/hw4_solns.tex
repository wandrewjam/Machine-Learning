%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Structured General Purpose Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{amsmath, amssymb, amsthm}
\usepackage{tikz}

%%%%%%%% Convenient Commands %%%%%%%
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\der}[2]{\frac{d #1}{d #2}}
\newcommand{\pder}[2]{\frac{d #1}{d #2}}
\newcommand{\inv}{^{-1}}
\newcommand{\mat}[1]{\textbf{#1}}
\newcommand{\eps}{\varepsilon}
\newcommand{\ds}{\displaystyle}
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\tn}{\textnormal}
\DeclareMathOperator{\sign}{sign}
\renewcommand{\labelenumi}{[\textbf{\alph{enumi}}]}

% %%%%%%%%% Theorem Commands %%%%%%%%%
% \newtheorem{thm}{Theorem}[section] %this creates theorems
% \newtheorem{cor}[thm]{Corollary}
% \newtheorem{prop}[thm]{Proposition}
% \newtheorem{dfn}[thm]{Definition}
% \newtheorem{lem}[thm]{Lemma}
% \newtheorem{rmk}[thm]{Remark}
% \newtheorem{exm}{Example}[section]

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\subsection{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsubsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
   
%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Homework\ \#4} % Assignment title
\newcommand{\hmwkDueDate}{Monday,\ October\ 23,\ 2017} % Due date
\newcommand{\hmwkClass}{CaltechX: Learning From Data} % Course/class
\newcommand{\hmwkClassTime}{} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Yaser Abu-Mostafa} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Andrew Watson} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\newpage
\tableofcontents
\newpage


\section{Generalization Error}

In Problems 1--3, we look at generalization bounds numerically. For $N > d_\tn{VC}$, use the simple approximate bound $N^{d_\tn{VC}}$ for the growth function $m_\mathcal{H}(N)$.

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
For an $\mathcal{H}$ with $d_\tn{VC} = 10$, if you want 95\% confidence that your generalization error is at most 0.05, what is the closest numerical approximation of the sample size that the VC generalization bound predicts?

\begin{enumerate}
	\item 400,000
	\item 420,000
	\item 440,000
	\item 460,000
	\item 480,000
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 2
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
There are a number of bounds on the generalization error $\epsilon$, all holding with probability at least $1 - \delta$. Fix $d_\tn{VC} = 50$ and $\delta = 0.05$ and plot these bounds as a function of $N$. Which bound is the smallest for very large $N$, say $N = 10,000$? Note that [\textbf{c}] and [\textbf{d}] are implicit bounds in $\epsilon$.

\begin{enumerate}
	\item Original VC bound: $\epsilon \leq \sqrt{\frac{8}{N} \ln\frac{4 m_\mathcal{H}(2N)}{\delta}}$
	\item Rademacher Penalty Bound: $\epsilon \leq \sqrt{\frac{2\ln(2N m_\mathcal{H}(N))}{N}} + \sqrt{\frac{2}{N}\ln\frac{1}{\delta}} + \frac{1}{N}$
	\item Parrondo and Van den Broek: $\epsilon \leq \sqrt{\frac{1}{N}\left(2\epsilon + \ln\frac{6m_\mathcal{H}(2N)}{\delta}\right)}$
	\item Devroye: $\epsilon \leq \sqrt{\frac{1}{2N}\left(4\epsilon(1 + \epsilon) + \ln\frac{4m_\mathcal{H}(N^2)}{\delta}\right)}$
	\item They are all equal.
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 3
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
For the same values of $d_\tn{VC}$ and $\delta$ of Problem 2, but for small $N$, say $N = 5$,
which bound is the smallest?

\begin{enumerate}
	\item Original VC bound: $\epsilon \leq \sqrt{\frac{8}{N} \ln\frac{4 m_\mathcal{H}(2N)}{\delta}}$
	\item Rademacher Penalty Bound: $\epsilon \leq \sqrt{\frac{2\ln(2N m_\mathcal{H}(N))}{N}} + \sqrt{\frac{2}{N}\ln\frac{1}{\delta}} + \frac{1}{N}$
	\item Parrondo and Van den Broek: $\epsilon \leq \sqrt{\frac{1}{N}\left(2\epsilon + \ln\frac{6m_\mathcal{H}(2N)}{\delta}\right)}$
	\item Devroye: $\epsilon \leq \sqrt{\frac{1}{2N}\left(4\epsilon(1 + \epsilon) + \ln\frac{4m_\mathcal{H}(N^2)}{\delta}\right)}$
	\item They are all equal.
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

\section{Bias and Variance}

Consider the case where the target function $f: [-1, 1] \rightarrow R$ is given by $f(x) = \sin(\pi x)$ and the input probability distribution is uniform on $[-1, 1]$. Assume that the training set has only two examples (picked independently), and that the learning algorithm produces the hypothesis that minimizes the mean squared error on the examples.

%----------------------------------------------------------------------------------------
%	PROBLEM 4
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
Assume the learning model consists of all hypotheses of the form $h(x) = ax$. What is the expected value, $\bar{g}(x)$, of the hypothesis produced by the learning algorithm (expected value with respect to the data set)? Express your $\bar{g}(x)$ as $\hat{a}x$, and round $\hat{a}$ to two decimal digits only, then match \emph{exactly} to one of the following answers.

\begin{enumerate}
	\item $\bar{g}(x) = 0$
	\item $\bar{g}(x) = 0.79x$
	\item $\bar{g}(x) = 1.07x$
	\item $\bar{g}(x) = 1.58x$
	\item None of the above
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 5
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
What is the closest value to the bias in this case?

\begin{enumerate}
	\item 0.1
	\item 0.3
	\item 0.5
	\item 0.7
	\item 1.0
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 6
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
What is the closest value to the variance in this case?

\begin{enumerate}
	\item 0.2
	\item 0.4
	\item 0.6
	\item 0.8
	\item 1.0
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 7
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
Now, let's change $\mathcal{H}$. Which of the following learning models has the least expected value of out-of-sample error?

\begin{enumerate}
	\item Hypotheses of the form $h(x) = b$
	\item Hypotheses of the form $h(x) = ax$
	\item Hypotheses of the form $h(x) = ax + b$
	\item Hypotheses of the form $h(x) = ax^2$
	\item Hypotheses of the form $h(x) = ax^2 + b$
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

\section{VC Dimension}

%----------------------------------------------------------------------------------------
%	PROBLEM 8
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
Assume $q \geq 1$ is an integer and let $m_\mathcal{H}(1) = 2$. What is the VC dimension of a hypothesis set whose growth function satisfies: $m_\mathcal{H}(N + 1) = 2m_\mathcal{H}(N) - {{N}\choose{q}}$? Recall that ${{M}\choose{m}} = 0$ when $m > M$.

\begin{enumerate}
	\item $q - 2$
	\item $q - 1$
	\item $q$
	\item $q + 1$
	\item None of the above
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 9
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, \hdots, \mathcal{H}_k$ with finite, positive VC dimensions $d_\tn{VC}(\mathcal{H}_k)$ (same input space $\mathcal{X}$), some of the following bounds are correct and some are not. Which among the correct ones is the tightest bound (the smallest range of values) on the VC dimension of the \textbf{intersection} of the sets: $d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right)$? (The VC dimension of an empty set or a singleton set is taken as zero)

\begin{enumerate}
	\item $0 \leq d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right) \leq \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
	\item $0 \leq d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right) \leq \min\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K$
	\item $0 \leq d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right) \leq \max\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K$
	\item $\min\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K \leq d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right) \leq \max\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K$
	\item $\min\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K \leq d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right) \leq \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 10
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, \hdots, \mathcal{H}_k$ with finite, positive VC dimensions $d_\tn{VC}(\mathcal{H}_k)$ (same input space $\mathcal{X}$), some of the following bounds are correct and some are not. Which among the correct ones is the tightest bound (the smallest range of values) on the VC dimension of the \textbf{union} of the sets: $d_\tn{VC}\left(\cap_{k=1}^K \mathcal{H}_k\right)$?

\begin{enumerate}
	\item $0 \leq d_\tn{VC}\left(\cup_{k=1}^K \mathcal{H}_k\right) \leq \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
	\item $0 \leq d_\tn{VC}\left(\cup_{k=1}^K \mathcal{H}_k\right) \leq K - 1 + \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
	\item $\min\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K \leq d_\tn{VC}\left(\cup_{k=1}^K \mathcal{H}_k\right) \leq \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
	\item $\max\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K \leq d_\tn{VC}\left(\cup_{k=1}^K \mathcal{H}_k\right) \leq \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
	\item $\max\{d_\tn{VC}(\mathcal{H}_k)\}_{k=1}^K \leq d_\tn{VC}\left(\cup_{k=1}^K \mathcal{H}_k\right) \leq K - 1 + \sum_{k=1}^K d_\tn{VC}(\mathcal{H}_k)$
\end{enumerate} % Question

\problemAnswer{ % Answer
	
}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------

\end{document}
