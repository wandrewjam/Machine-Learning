{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target():\n",
    "    # Generate the target function f\n",
    "    div_points = np.random.uniform(low=-1, high=1, size=(2, 2))\n",
    "    w1 = (div_points[1, 1] - div_points[0, 1])/(div_points[1, 0] - div_points[0, 0])\n",
    "    w0 = div_points[0, 1] - div_points[0, 0]*w1\n",
    "    w = np.array([w0, w1, -1])\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(num_points, w):\n",
    "    # Generate the test points and classify\n",
    "    test_points = np.ones([num_points, 4])\n",
    "    test_points[:, 1:3] = np.random.uniform(low=-1, high=1, size=(num_points, 2))\n",
    "    test_points[:, 3] = np.sign(np.dot(test_points[:, 0:3], w))\n",
    "    return test_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_regression(training, g_init=np.zeros(3), tol=1e-6, max_iter=10**4, eta=0.01):\n",
    "    g = np.copy(g_init)\n",
    "    iters = 0\n",
    "    n_points, n_cols = training.shape\n",
    "    y = training[:, -1]\n",
    "    X = training[:, 0:n_cols-1]\n",
    "    error = 1\n",
    "\n",
    "    while error > tol and iters < max_iter:\n",
    "        old = np.copy(g)\n",
    "        for i in np.random.permutation(n_points):\n",
    "            xn = X[i,:]\n",
    "            yn = y[i]\n",
    "            g += eta*(yn*xn)/(1 + np.exp(yn*np.dot(xn, g)))\n",
    "        iters += 1\n",
    "        error = np.linalg.norm(g - old)\n",
    "\n",
    "    return g, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.101768676083\n",
      "343.6\n"
     ]
    }
   ],
   "source": [
    "NTRIALS=100\n",
    "NPOINTS=100\n",
    "MCPOINTS = 10**6\n",
    "e_out = np.zeros(NTRIALS)\n",
    "iters = np.zeros(NTRIALS)\n",
    "for i in range(0, NTRIALS):\n",
    "    w = generate_target()\n",
    "    training = generate_sample(NPOINTS, w)\n",
    "    g, iters[i] = log_regression(training, tol=0.01)\n",
    "    mcdata = generate_sample(MCPOINTS, w)\n",
    "    Xmc = mcdata[:,0:3]\n",
    "    ymc = mcdata[:,3]\n",
    "    e_out[i] = np.mean(np.log(1+np.exp(-ymc*np.dot(Xmc, g))))\n",
    "\n",
    "print(np.mean(e_out))\n",
    "print(np.mean(iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
