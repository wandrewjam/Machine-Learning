{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "# sp.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## Linear Regression Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5acc708660fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "N = sp.symbols('N')\n",
    "s, d = 0.1, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.solve(s**2*(1 - (d+1)/N) - 0.008, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = sp.symbols('u v')\n",
    "E = (u*sp.exp(v)-2*v*sp.exp(-u))**2\n",
    "E.diff(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.diff(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E(x):\n",
    "    u = x[0]\n",
    "    v = x[1]\n",
    "    return (u*np.exp(v) - 2*v*np.exp(-u))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_E(x):\n",
    "    grad = np.zeros(2)\n",
    "    u = x[0]\n",
    "    v = x[1]\n",
    "    grad[0] = 2*(u*np.exp(v) - 2*v*np.exp(-u))*(np.exp(v) + 2*v*np.exp(-u))\n",
    "    grad[1] = 2*(u*np.exp(v) - 2*v*np.exp(-u))*(u*np.exp(v) - 2*np.exp(-u))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_descent(E, grad_E, init=np.ones(2), eta=0.1, tol=1e-6, max_iter=10**4):\n",
    "    iters=0\n",
    "    u = init\n",
    "    error = E(u)\n",
    "    while error > tol and iters < max_iter:\n",
    "        u = u - eta*grad_E(u)\n",
    "        error = E(u)\n",
    "        iters = iters + 1\n",
    "        print(u)\n",
    "    return u, iters, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_descent(E, grad_E, init=np.ones(2), eta=0.1, tol=1e-6, max_iter=10**5):\n",
    "    iters=0\n",
    "    u = init\n",
    "    error = E(u)\n",
    "    while error > tol and iters < max_iter:\n",
    "        u[0] = u[0] - eta*grad_E(u)[0]\n",
    "        u[1] = u[1] - eta*grad_E(u)[1]\n",
    "        error = E(u)\n",
    "        iters = iters+1\n",
    "        print(u)\n",
    "    return u, iters, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_g, iters_g, error_g = grad_descent(E, grad_E, tol=1e-14)\n",
    "print(' ')\n",
    "u_c, iters_c, error_c = coord_descent(E, grad_E, init=np.ones(2), tol=1e-30, max_iter=15)\n",
    "print(u_g, u_c)\n",
    "print(iters_g, iters_c)\n",
    "print(error_g, error_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.linspace(0,2), np.linspace(0,2))\n",
    "def error(x, y):\n",
    "    return (x*np.exp(y) - 2*y*np.exp(-x))**2\n",
    "\n",
    "Z = error(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target(low=-1, high=1):\n",
    "    # Generate the target function f\n",
    "    div_points = np.random.uniform(low=low, high=high, size=(2, 2))\n",
    "    w1 = (div_points[1, 1] - div_points[0, 1])/(div_points[1, 0] - div_points[0, 0])\n",
    "    w0 = div_points[0, 1] - div_points[0, 0]*w1\n",
    "    w = np.array([w0, w1, -1])\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(num_points, w, low=-1, high=1):\n",
    "    # Generate the test points and classify\n",
    "    test_points = np.ones([num_points, 4])\n",
    "    test_points[:, 1:3] = np.random.uniform(low=low, high=high, size=(num_points, 2))\n",
    "    test_points[:, 3] = np.sign(np.dot(test_points[:, 0:3], w))\n",
    "    return test_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression(training, g_init=np.zeros(3), tol=1e-6, max_iter=10**4, eta=0.1):\n",
    "    g = g_init\n",
    "    iters = 0\n",
    "    n_points, n_cols = training.shape\n",
    "    y = training[:, -1]\n",
    "    X = training[:, 0:n_cols-1]\n",
    "    error = tol+1\n",
    "\n",
    "    while error > tol and iters < max_iter:\n",
    "        old = g\n",
    "        for i in np.random.permutation(n_points):\n",
    "            xn = X[i,:]\n",
    "            yn = y[i]\n",
    "            g = g + eta*(yn*xn)/(1 + np.exp(yn*np.dot(xn, g)))\n",
    "        iters += 1\n",
    "        error = np.linalg.norm(g - old)\n",
    "\n",
    "    return g, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.337346593227\n",
      "1149.4\n"
     ]
    }
   ],
   "source": [
    "NTRIALS=10\n",
    "NPOINTS=100\n",
    "MCPOINTS = 10**6\n",
    "mcdata = np.ones([MCPOINTS, 3])\n",
    "mcdata[:, 1:3] = np.random.random([MCPOINTS, 2])\n",
    "e_out = np.zeros(NTRIALS)\n",
    "g = np.zeros([NTRIALS, 3])\n",
    "iters = np.zeros(NTRIALS)\n",
    "for i in range(0, NTRIALS):\n",
    "    w = generate_target()\n",
    "    training = generate_sample(NPOINTS, w)\n",
    "    g, iters[i] = log_regression(training, tol=0.01)\n",
    "    g = -g/g[2]\n",
    "    e_out[i] = np.mean(np.log(1+np.exp(-np.sign(np.dot(mcdata,w))*np.dot(mcdata,g))))\n",
    "#     print(w, g, iters)\n",
    "\n",
    "print(np.mean(e_out))\n",
    "print(np.mean(iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1 = w[0], w[1]\n",
    "g0, g1 = g[0], g[1]\n",
    "\n",
    "# Split the test points into the two classification groups\n",
    "positives = training[training[:,-1]>0,:]\n",
    "negatives = training[training[:,-1]<0,:]\n",
    "\n",
    "# Plot f, g, and \\mathbf{x}\n",
    "x = np.linspace(0,1)\n",
    "xpos = positives[:,1]\n",
    "ypos = positives[:,2]\n",
    "xneg = negatives[:,1]\n",
    "yneg = negatives[:,2]\n",
    "\n",
    "plt.plot(xneg,yneg,'.g')\n",
    "plt.plot(xpos,ypos,'.r')\n",
    "plt.plot(x,w1*x+w0)\n",
    "plt.plot(x,g1*x+g0,'--k')\n",
    "plt.axis([0,1,0,1])\n",
    "#plt.legend(['Negative','Positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(training, g_init=np.zeros(3), max_iter=10**5, pocket=True):\n",
    "    # Implement PLA, count the iterations to convergence, and the error\n",
    "    g = g_init\n",
    "    iters = 0\n",
    "    n_points, n_cols = training.shape\n",
    "    \n",
    "    test_points = np.zeros([n_points, n_cols+2])\n",
    "    test_points[:, 0:n_cols] = training\n",
    "    test_points[:, -2] = np.sign(np.dot(test_points[:, 0:3], g))\n",
    "    test_points[:, -1] = np.log(1+np.exp(-test_points[:, ncols-1]*))\n",
    "    wrong = test_points[test_points[:, -1] < 1, :]\n",
    "    nrows = wrong.shape[0]\n",
    "    \n",
    "    if pocket:\n",
    "        minrows = nrows\n",
    "        best = g\n",
    "    \n",
    "    while nrows > 0 and iters < max_iter:\n",
    "        if nrows == 1:\n",
    "            g = g + wrong[0, 0:3]*wrong[0, 3]\n",
    "        else:\n",
    "            rind = np.random.randint(0, nrows)\n",
    "            g = g + wrong[rind, 0:3]*wrong[rind, 3]\n",
    "        \n",
    "        iters += 1\n",
    "        test_points[:, -2] = np.sign(np.dot(test_points[:, 0:3], g))\n",
    "        test_points[:, -1] = test_points[:, -3] == test_points[:, -2]\n",
    "        wrong = test_points[test_points[:, -1] < 1, :]\n",
    "        nrows = wrong.shape[0]\n",
    "        if pocket and nrows < minrows:\n",
    "            minrows = nrows\n",
    "            best = g\n",
    "    \n",
    "    if pocket:\n",
    "        g = best\n",
    "        \n",
    "    return g, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 10**2\n",
    "w = generate_target()\n",
    "training = generate_sample(npoints, w)\n",
    "inds = np.random.choice(npoints, npoints//10)\n",
    "training[inds, -1] = -training[inds, -1]\n",
    "g, iters = perceptron(training)\n",
    "g = -g/g[2]\n",
    "print(g)\n",
    "print(w)\n",
    "print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1 = w[0], w[1]\n",
    "g0, g1 = g[0], g[1]\n",
    "\n",
    "# Split the test points into the two classification groups\n",
    "positives = training[training[:,-1]>0,:]\n",
    "negatives = training[training[:,-1]<0,:]\n",
    "\n",
    "# Plot f, g, and \\mathbf{x}\n",
    "x = np.linspace(0,1)\n",
    "xpos = positives[:,1]\n",
    "ypos = positives[:,2]\n",
    "xneg = negatives[:,1]\n",
    "yneg = negatives[:,2]\n",
    "\n",
    "plt.plot(xneg,yneg,'.g')\n",
    "plt.plot(xpos,ypos,'.r')\n",
    "plt.plot(x,w1*x+w0)\n",
    "plt.plot(x,g1*x+g0,'--k')\n",
    "plt.axis([0,1,0,1])\n",
    "#plt.legend(['Negative','Positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
